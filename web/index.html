<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | CS, Georgia Tech | Fall 2020: CS 4476</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Image Captioning For Manga Translation</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Weiyao Tang, Zhaoran Ma, Jiachen Ren, Haoran Zhang, May Vy Le</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2020: CS 4476</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

<!--Please see <a href="http://vision.cs.utexas.edu/projects/adapted_attributes/">this</a> for an example of how to lay out the various details of your project. You may need to provide more details than this, beause you will not be submitting an associated paper to accompany the webpage. So the page should be self-contained-->

<!-- Goal -->
<h3>Abstract</h3>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<!--h3>Teaser figure</h3>
A figure that conveys the main idea behind the project or the main application being addressed.
<br><br-->
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
<img style="height: 400px;" alt="" src="manga0.png">
</div>

<br><br>
<!-- Introduction -->
<h3>Introduction</h3>
Manga have been around for over centuries and hundreds of mangas are printed everyday in Japan. However, manga has recently gained a rise of popularity and one of the reasons is due to the internet; manga are now digitized into web content and there are now many hosting websites where anyone can upload their web manga and users can read for free. However, most manga are written in Japanese or Korean, and to share manga to non-Japanese/Korean readers, a translation to English is needed. Yet, any translation work is time consuming labor since there is no automatic method to translate the writing in manga into any other language.  The goal of this project is that by using image captioning, a user can input an image with manga in the original language to the system, utilizing text detection and identification model to get the manga inside it and the desired output is the manga with the text translated to English. 

<!--Motivation behind the problem you are solving, what applications it has, any brief background on the particular domain you are working in (if not regular RBG photographs), etc. If you are using a new way to solve an existing problem, briefly mention and describe the existing approaches and tell us how your approach is new.-->

<br><br>
<!-- Approach -->
<h3>Approach</h3>
<!--Describe very clearly and systematically your approach to solve the problem. Tell us exactly what existing implementations you used to build your system. Tell us what obstacles you faced and how you addressed them. Justify any design choices or judgment calls you made in your approach.-->

<h4>1. Text Searching</h4>
Using Mask R-CNN, we can detect where the text is located in the image and extract these characters for next step.

<h4>2. Token/Character Identification</h4>
Applying OCR to text tokens and extract individual Japanese characters in sequence from those images

<h4>3. Inserting Text Back to Image</h3>
Using machine translation API to translate the text content extracted to English


<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
<br>
When documents are clearly laid out and have global structure (for example, a business letter), existing tools for OCR can perform quite well. In Manga, first, the document of interest occurs alongside some background objects . Second, the text within the document is highly unstructured and therefore it is beneficial to separately identify all the possible text blocks. Inspired by fully convolutional networks, we came up with the idea of modifying the model MaskRCNN and training it with OCR-relevant datasets leads to an effective approach for text location, which is consisted of two steps.  First, CNN is adopted to detect text blocks, from which character candidates are extracted. Then FPN is used to predict the corresponding segmentation masks. Last, segmentation mask is used to ﬁnd suitable rectangular bounding boxes for the text instances. The model generates bounding boxes and segmentation masks for each instance of an object in the image.
<br> <br>
<div style="text-align: center;">
<img style="height: 500px;" alt="" src="manga2.png">

</div>

<br><br>

For the token/character identification, we plan to identify the Japanese characters in the regions where we detect some text in the first step. Here we want to apply Optical Character Recognition to text images and extract individual Japanese characters in sequence from those images. We already found some code that implements this model ([Link 1] and [Link 2]). At the same time, we expect our output of this step to be some form of sentences so that we can translate the sentences in Japanese to English context later. Since text in manga is usually aligned vertically from top to bottom, we want to first identify separate text columns by detecting blank areas between them, and this can be possibly implemented using a simple gradient energy map. After getting the columns, we may also want to segment the columns on a character-level basis (including punctuations). Then we plan to apply the recognition model we mentioned above to classify each individual character and concatenate them into complete sentences. 

<br><br>

<div style="text-align: center;">
<img style="height: 500px;" alt="" src="manga3.png">


<br><br>

<!-- Main Results Figure > 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br-->

<!-- Results >
<h3>Qualitative results</h3>
Show several visual examples of inputs/outputs of your system (success cases and failures) that help us better understand your approach.
<br><br-->

<!-- Main Results Figure > 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="qual_results.png">
</div>
<br><br-->




  <hr>
  <footer> 
  <p>© You Name Here</p>
  </footer>
</div>
</div>

<br><br>

</body></html>